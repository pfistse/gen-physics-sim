defaults:
  - model: consistency_model
  - tracking: wandb
  - data: default
  - logging: default
  - evaluation: default
  - _self_

train: true
test: true
seed: 42

ckpt_path: null

trainer:
  _target_: pytorch_lightning.Trainer
  max_epochs: 3100
  accelerator: "gpu"
  strategy: "ddp"
  devices: [1]
  precision: 32
  check_val_every_n_epoch: 10
  deterministic: true

callbacks:
  model_checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    dirpath: "checkpoints"
    monitor: "val_loss"
    filename: "model-{epoch:02d}-{val_loss:.4f}"
    save_top_k: 3
    mode: "min"
    save_last: true
    save_on_train_epoch_end: false
    auto_insert_metric_name: false
  learning_rate_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: "epoch"
  rich_progress_bar:
    _target_: pytorch_lightning.callbacks.RichProgressBar

hydra:
  job:
    chdir: true
  run:
    dir: runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
